{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Fine-tune BERT on a Mock Sentiment Dataset"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "!pip install transformers datasets accelerate -q",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Load dataset"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from datasets import load_dataset\n\ndataset = load_dataset('csv', data_files={'train': 'mock_sentiment.csv', 'validation': 'mock_sentiment.csv'})",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Tokenize"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n\ndef tokenize_function(examples):\n    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=64)\n\nencoded_dataset = dataset.map(tokenize_function, batched=True)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Load model"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Training"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    max_steps=100,\n    evaluation_strategy='steps',\n    eval_steps=10,\n    logging_steps=10,\n    save_strategy='no'\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=encoded_dataset['train'],\n    eval_dataset=encoded_dataset['validation'],\n)\n\ntrainer.train()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Evaluate"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "metrics = trainer.evaluate()\nprint(metrics)",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
